---
title: "University of Alberta 
 Faculty of Engineering Research Output"
author: "Alison Henry"
date: "16 October 2017"
output: 
        word_document:
                df_print: kable
bibliography: ROA2017.bib
csl: chemical-engineering-journal.csl
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE, message = FALSE, warning  = FALSE)
```
A report to examine the publication output of the Univeristy of Alberta Faculty of Engineering. Searches were conducted using Web of Science, and limited to the five publication years from 2012-2016. 

```{r package installation}
##Install and load needed packages

##install.packages("bibliometrix", dependencies = TRUE)
##install.packages("splitstackshape")
##install.packages("tidyverse")
##install.packages("viridis")
##install.packages("knitr")

library(bibliometrix)
library(splitstackshape)
library(tidyverse)
library(stringr)
library(viridis)
library(knitr)
```
Initial processing of the data was accomplished with the Bibliometrix package written by Massimo Aria and Corrado Cuccurullo[@RefWorks:doc:59d24e48e4b0b590b97a2290]. This allowed easy conversion of records into a data frame to facilitate further processing.

```{r read in bibtex files} 
## Read in downloaded files and convert to dataframe
filePaths1 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
D1 <- do.call("readFiles", as.list(filePaths1)) 
M1 <- convert2df(D1, dbsource = "isi", format = "bibtex")

##filePaths2 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D2 <- do.call("readFiles", as.list(filePaths2)) 
##M2 <- convert2df(D2, dbsource = "isi", format = "bibtex")

##filePaths3 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D3 <- do.call("readFiles", as.list(filePaths3)) 
##M3 <- convert2df(D3, dbsource = "isi", format = "bibtex")

##filePaths4 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D4 <- do.call("readFiles", as.list(filePaths4)) 
##M4 <- convert2df(D4, dbsource = "isi", format = "bibtex")

##filePaths5 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D5 <- do.call("readFiles", as.list(filePaths5)) 
##M5 <- convert2df(D5, dbsource = "isi", format = "bibtex")

##filePaths6 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D6 <- do.call("readFiles", as.list(filePaths6)) 
##M6 <- convert2df(D6, dbsource = "isi", format = "bibtex")

##filePaths7 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D7 <- do.call("readFiles", as.list(filePaths7)) 
##M7 <- convert2df(D7, dbsource = "isi", format = "bibtex")

##filePaths8 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D8 <- do.call("readFiles", as.list(filePaths8)) 
##M8 <- convert2df(D8, dbsource = "isi", format = "bibtex")

##filePaths9 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D9 <- do.call("readFiles", as.list(filePaths9)) 
##M9 <- convert2df(D9, dbsource = "isi", format = "bibtex")

##filePaths10 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D10 <- do.call("readFiles", as.list(filePaths10)) 
##M10 <- convert2df(D10, dbsource = "isi", format = "bibtex")

##filePaths11 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D11 <- do.call("readFiles", as.list(filePaths11)) 
##M11 <- convert2df(D11, dbsource = "isi", format = "bibtex")

##filePaths12 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D12 <- do.call("readFiles", as.list(filePaths12)) 
##M12 <- convert2df(D12, dbsource = "isi", format = "bibtex")

##filePaths13 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D13 <- do.call("readFiles", as.list(filePaths13)) 
##M13 <- convert2df(D13, dbsource = "isi", format = "bibtex")

##filePaths14 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D14 <- do.call("readFiles", as.list(filePaths14)) 
##M14 <- convert2df(D14, dbsource = "isi", format = "bibtex")

##filePaths15 = dir("./WoSdata", pattern = "*.bib", recursive = TRUE, full.names = TRUE) 
##D15 <- do.call("readFiles", as.list(filePaths15)) 
##M15 <- convert2df(D15, dbsource = "isi", format = "bibtex")

```

```{r subset data}
## Keep only selected columns: UT, DT, C1, DT, TC, PY
mydata1 <- select(M1, UT, C1, DT, PY, TC)
```
Data was kept for article identifiers, addresses, document type, publication year and number of citations. The address field is first split to separate co-author addresses.

```{r separate authors}
## Separate authors into single observations
tidy_data1 <- cSplit(mydata1, "C1", sep = ";", direction = "long")
```
Confirm no addresses were lost in the split:

```{r test for drops, include=TRUE, echo=FALSE}
##Test that there were no unintended drops
count <- sum(str_count(mydata1$C1, ";"))
ifelse(count + nrow(mydata1) == nrow(tidy_data1), "No drops", "Warning") 
```

Non-UofA addresses are then removed and departmental affiliations assigned. This was done by comparing the abbreviations in the address field to a list of potential abbreviations with associated department names. Addresses without a match were assigned "Other" and removed. For a more detailed analysis, the "Other"s should be examined to identify potential Faculty of Engineering affiliation. A quick skim of the list shows that most were from other U of A departments (e.g. Physics, Earth and Atmospheric Sciences), but some listed only Univ Alberta, so would need a list of faculty members to be properly assigned. 

```{r limit to UofA addresses}
## Remove non-UofA addresses
AlbertaData <- tidy_data1[grep("UNIV ALBERTA", tidy_data1$C1), ]
```
```{r Assign departmental affiliation}

## Identify departmental affiliations
deptUrl <- ("https://docs.google.com/spreadsheets/d/e/2PACX-1vTMpIJn2N9pV13zRhYKRdOOAUfvHhKF6dqUzMWhnk3_eaBgPD8XT6UJBuAXfyoWfA0qfvaO4LyQpfJA/pub?output=csv")
depts <- read.csv(deptUrl)
abs <- as.character(depts$Abbreviation)
##AlbertaData$Department <- ifelse(grepl(paste(abs, collapse = "|"), AlbertaData$C1), abs, "Other")
##AlbertaData$Department <- str_replace(as.character(AlbertaData$Department), as.character(depts$Abbreviation), as.character(depts$Name))

AlbertaData$Department <- ifelse(grepl(" CHEM ", AlbertaData$C1), "Chemical and Materials Engineering",
                     ifelse(grepl(" MAT ", AlbertaData$C1), "Chemical and Materials Engineering",
                     ifelse(grepl(" CIVIL ", AlbertaData$C1), "Civil and Environmental Engineering",
                     ifelse(grepl(" SCH MIN ", AlbertaData$C1), "Civil and Environmental Engineering",
                     ifelse(grepl(" PETR ", AlbertaData$C1), "Civil and Environmental Engineering",
                     ifelse(grepl(" ELECT ", AlbertaData$C1), "Electrical and Computer Engineering",
                     ifelse(grepl(" MECH ", AlbertaData$C1), "Mechanical Engineering",
                     ifelse(grepl(" BIOMED ", AlbertaData$C1), "Biomedical Engineering",
                     ifelse(grepl(" RESOURCES ", AlbertaData$C1), "Civil and Environmental Engineering",
                     ifelse(grepl(" TRANSPORTATION ", AlbertaData$C1), "Civil and Environmental Engineering",
                            "Other"))))))))))

```

```{r examine "Other"}
## check the "other"s for articles that should be kept
Other <- filter(AlbertaData, Department == "Other")
##View(Other)
engData <- filter(AlbertaData, Department != "Other")
```
Whole counting is used, so that each publication is counted only once for the institution, but articles with authors from different departments will count toward the totals for each of those departments.

##Results
Number of articles per year
```{r filter and group data}
deptData <- group_by(engData, Department) 
fourDepts <- filter(deptData, Department != "Biomedical Engineering")

## set colour scheme for charts
cbpalette <- viridis(5)
```
With BioMed:

```{r include = TRUE, echo = FALSE}
ppy <- ggplot(unique(deptData), aes(PY)) 
ppy + geom_bar(aes(fill=Department)) + theme_bw(base_family = "Times") + labs(title = "Articles per Year, by Department", x = "Publication Year", y = "Articles") + theme(plot.title = element_text(hjust = 0.5), legend.position = "bottom", legend.direction = "vertical", legend.title.align = 0.5) + scale_fill_manual(values = cbpalette, guide = guide_legend(ncol=2)) 
```
Without BioMed:

```{r include = TRUE, echo = FALSE}
ppy4<- ggplot(unique(fourDepts), aes(PY)) 
ppy4 + geom_bar(aes(fill=Department)) + theme_minimal(base_family = "Times") + labs(title = "Articles per Year, by Department", x = "Publication Year", y = "Articles") + scale_fill_manual(values = cbpalette[2:5], guide = guide_legend(ncol=2)) + theme(plot.title = element_text(hjust = 0.5), legend.position = "bottom", legend.direction = "vertical", legend.title.align = 0.5)
```
The initial data load contained three types of publications: Articles, Book Chapters, and Conference Proceedings.

Mean number of citations per publication

```{r citation summary, include = TRUE, echo = FALSE, results='asis'}
## Report number of citations per department
tab1 <- summarise(deptData, 'Times Cited' = mean(TC))
tab1[,sapply(tab1, is.numeric)] <- sapply(tab1[,sapply(tab1, is.numeric)], function(x) sprintf("%1.2f", x))
tab1
```
Mean citations per article using only document type "article"

```{r article citation summary, include = TRUE, echo = FALSE, results='asis'}
articleData <- filter(deptData, DT == "ARTICLE ")
tab2 <- summarise(articleData, 'Times Cited' = mean(TC))
tab2[,sapply(tab2, is.numeric)] <- sapply(tab2[,sapply(tab2, is.numeric)], function(x) sprintf("%1.2f", x))
tab2
```
#References